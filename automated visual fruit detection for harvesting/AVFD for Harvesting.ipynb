{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing hsv+contour+gaussian blur on pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy image into another varibale for later use\n",
    "# adjusting color space using hsv\n",
    "# using blur to reduce noise\n",
    "# apply mask using hsv\n",
    "# canny edge \n",
    "# dilate\n",
    "# call contour function\n",
    "# display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "#cv2.namedWindow(\"Parameters\")\n",
    "#cv2.resizeWindow(\"Parameters\",640,240)\n",
    "cv2.createTrackbar(\"Threshold1\",\"Tracking\",107,255,nothing)\n",
    "cv2.createTrackbar(\"Threshold2\",\"Tracking\",114,255,nothing)\n",
    "cv2.createTrackbar(\"Area\",\"Tracking\",5000,30000,nothing)\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) #in the last parameter we are getting all the stored contour points but if we use the other one which is cv2.CHAIN_APPROX_SIMPLE then this will compress the values and we will get lesser number of points so we write it as NONE so that we get all of the points.\n",
    "    #in external it retrives only the external outer corners\n",
    "    #cv2.drawContours(imgContour, contours, -1, (255, 0, 255), 7)#last 2 parameters is colour and width of boundary\n",
    "    \n",
    "    for cnt in contours:\n",
    "        #now we are looking into the area of each contour. so basically by putting a limit on the area we are reducing the noise like small dots outside the object\n",
    "        #cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "        area=cv2.contourArea(cnt)\n",
    "        areaMin = cv2.getTrackbarPos(\"Area\", \"Tracking\")\n",
    "        if area>areaMin:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            #now finding the corner points but before that we need to find the length of the contours\n",
    "            peri=cv2.arcLength(cnt,True)#true basically means that the contour is closed and this will give us the value of the length of the perimeter and we will use the perimeter to approximate what type of shape this is.\n",
    "            #we will use the perimeter to approximate what type of shape this is.\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)#giving it resolution and then defining that this is a closed contour. This approximation array will have a certain amount of points and these points can determine whether its a square or any other shape.\n",
    "            #This approximation array will have a certain amount of points and these points can determine whether its a square or any other shape.\n",
    "            print(len(approx)) #printing out the number of points. based on the number of points we can later generalise the shape.\n",
    "            #now lets create a bounding box\n",
    "            x, y, w, h=cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5) #2nd arg is initial points. 3rd argument is the final corner of the rectangle or the bounding box.after that color followed by width\n",
    "            #now we are going to display our values so that we can easily see the number of points detected and the area detected.\n",
    "            cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x, y - 42), cv2.FONT_HERSHEY_COMPLEX, .7,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x, y-27), cv2.FONT_HERSHEY_COMPLEX, 0.7,\n",
    "                        (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "while True:\n",
    "    frame = cv2.imread('apple (281).jpg')\n",
    "    imgContour = frame.copy()\n",
    "    imgBlur = cv2.GaussianBlur(frame, (7, 7), 1)#using kernel of 7 by 7 and 1 iteration\n",
    "\n",
    "    hsv = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "    \n",
    "    l_b=np.array([l_h,l_s,l_v])\n",
    "    u_b=np.array([u_h,u_s,u_v])\n",
    "    \n",
    "    mask=cv2.inRange(hsv, l_b, u_b)\n",
    "    \n",
    "    res=cv2.bitwise_and(frame, frame,mask=mask)\n",
    "    \n",
    "    threshold1 = cv2.getTrackbarPos(\"Threshold1\", \"Tracking\")\n",
    "    threshold2 = cv2.getTrackbarPos(\"Threshold2\", \"Tracking\")\n",
    "    imgCanny = cv2.Canny(mask,threshold1,threshold2)\n",
    "    kernel = np.ones((5, 5)) #defining a kernel for the dilation function. \n",
    "    imgDil = cv2.dilate(imgCanny, kernel, iterations=1)#dilation function is used to remove noise from the image.\n",
    "    getContours(imgDil,imgContour)\n",
    "    \n",
    "    imgStack = stackImages(0.8,([frame,mask,res],\n",
    "                               [imgCanny,imgDil,imgContour]))\n",
    "    \n",
    "    cv2.imshow('result',imgStack)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    '''ret, thresh = cv2.threshold(mask, 127, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)#2nd arg is contour retrieval mode,contour approxiation method\n",
    "    #hierarchy contains information of image topology\n",
    "    #RETR_EXTERNAL retrives only the external outer corners\n",
    "    #TREE retrives all the contours and constructs a full hierarchy\n",
    "    print(\"Number of contours = \" + str(len(contours)))#this will give the number of contours in the image\n",
    "    print(contours[0])\n",
    "\n",
    "    cv2.drawContours(mask, contours, -1, (0, 255, 0), 3)#3rd arg is contour indexes. if we give that -1 than its going to find all the 9 contours in the image. if we give index 0 then first contour will be found out in the image.similarly u can go from 0 to 8 as total contours are 9\n",
    "\n",
    "    cv2.drawContours(res, contours, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('result',res)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break'''\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply morph in above code and try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing hsv+contour+gaussian blur in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "8\n",
      "11\n",
      "11\n",
      "13\n",
      "9\n",
      "13\n",
      "12\n",
      "9\n",
      "9\n",
      "13\n",
      "11\n",
      "9\n",
      "10\n",
      "11\n",
      "10\n",
      "11\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "13\n",
      "12\n",
      "12\n",
      "9\n",
      "7\n",
      "11\n",
      "13\n",
      "12\n",
      "12\n",
      "11\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "11\n",
      "10\n",
      "9\n",
      "13\n",
      "12\n",
      "14\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "9\n",
      "11\n",
      "11\n",
      "10\n",
      "11\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "12\n",
      "11\n",
      "11\n",
      "12\n",
      "10\n",
      "11\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "11\n",
      "11\n",
      "13\n",
      "11\n",
      "10\n",
      "9\n",
      "11\n",
      "10\n",
      "10\n",
      "9\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "10\n",
      "14\n",
      "14\n",
      "11\n",
      "11\n",
      "11\n",
      "13\n",
      "9\n",
      "10\n",
      "12\n",
      "14\n",
      "12\n",
      "12\n",
      "11\n",
      "12\n",
      "10\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "12\n",
      "10\n",
      "9\n",
      "11\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "13\n",
      "8\n",
      "10\n",
      "12\n",
      "8\n",
      "12\n",
      "10\n",
      "10\n",
      "8\n",
      "11\n",
      "10\n",
      "9\n",
      "12\n",
      "12\n",
      "10\n",
      "12\n",
      "9\n",
      "10\n",
      "8\n",
      "11\n",
      "10\n",
      "11\n",
      "11\n",
      "9\n",
      "12\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "12\n",
      "10\n",
      "12\n",
      "9\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "14\n",
      "10\n",
      "12\n",
      "12\n",
      "10\n",
      "10\n",
      "9\n",
      "12\n",
      "10\n",
      "13\n",
      "11\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "12\n",
      "10\n",
      "8\n",
      "10\n",
      "11\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "#cv2.namedWindow(\"Parameters\")\n",
    "#cv2.resizeWindow(\"Parameters\",640,240)\n",
    "cv2.createTrackbar(\"Threshold1\",\"Tracking\",107,255,nothing)\n",
    "cv2.createTrackbar(\"Threshold2\",\"Tracking\",114,255,nothing)\n",
    "cv2.createTrackbar(\"Area\",\"Tracking\",5000,30000,nothing)\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) #in the last parameter we are getting all the stored contour points but if we use the other one which is cv2.CHAIN_APPROX_SIMPLE then this will compress the values and we will get lesser number of points so we write it as NONE so that we get all of the points.\n",
    "    cv2.drawContours(imgContour, contours, -1, (255, 0, 255), 7)#last 2 parameters is colour and width of boundary\n",
    "\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "        area=cv2.contourArea(cnt)\n",
    "        areaMin = cv2.getTrackbarPos(\"Area\", \"Tracking\")\n",
    "        if area>areaMin:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            #now finding the corner points but before that we need to find the length of the contours\n",
    "            peri=cv2.arcLength(cnt,True)#true basically means that the contour is closed and this will give us the value of the length of the perimeter and we will use the perimeter to approximate what type of shape this is.\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)#giving it resolution and then defining that this is a closed contour. This approximation array will have a certain amount of points and these points can determine whether its a square or any other shape.\n",
    "            print(len(approx))\n",
    "            #now lets create a bounding box\n",
    "            x, y, w, h=cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5) #2nd arg is initial points. 3rd argument is the final corner of the rectangle or the bounding box.after that color followed by width\n",
    "            #now we are going to display our values so that we can easily see the number of points detected and the area detected.\n",
    "            cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, .7,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"fruit detected: Tomato \", (x + w + 20, y + 70), cv2.FONT_HERSHEY_COMPLEX, 0.7,\n",
    "                        (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    #frame = cv2.imread('apple (281).jpg')\n",
    "    imgContour = frame.copy()\n",
    "    imgBlur = cv2.GaussianBlur(frame, (7, 7), 1)#using kernel of 7 by 7\n",
    "\n",
    "    hsv = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "    \n",
    "    l_b=np.array([l_h,l_s,l_v])\n",
    "    u_b=np.array([u_h,u_s,u_v])\n",
    "    \n",
    "    mask=cv2.inRange(hsv, l_b, u_b)\n",
    "    \n",
    "    res=cv2.bitwise_and(frame, frame,mask=mask)\n",
    "    \n",
    "    threshold1 = cv2.getTrackbarPos(\"Threshold1\", \"Tracking\")\n",
    "    threshold2 = cv2.getTrackbarPos(\"Threshold2\", \"Tracking\")\n",
    "    imgCanny = cv2.Canny(mask,threshold1,threshold2)\n",
    "    kernel = np.ones((5, 5)) #defining a kernel for the dilation function. \n",
    "    imgDil = cv2.dilate(imgCanny, kernel, iterations=1)#dilation function is used to remove noise from the image.\n",
    "    getContours(imgDil,imgContour)\n",
    "    \n",
    "    imgStack = stackImages(0.8,([frame,mask,res],\n",
    "                               [imgDil,imgCanny,imgContour]))\n",
    "    \n",
    "    cv2.imshow('result',imgStack)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    '''ret, thresh = cv2.threshold(mask, 127, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)#2nd arg is contour retrieval mode,contour approxiation method\n",
    "    #hierarchy contains information of image topology\n",
    "    #RETR_EXTERNAL retrives only the external outer corners\n",
    "    #TREE retrives all the contours and constructs a full hierarchy\n",
    "    print(\"Number of contours = \" + str(len(contours)))#this will give the number of contours in the image\n",
    "    print(contours[0])\n",
    "\n",
    "    cv2.drawContours(mask, contours, -1, (0, 255, 0), 3)#3rd arg is contour indexes. if we give that -1 than its going to find all the 9 contours in the image. if we give index 0 then first contour will be found out in the image.similarly u can go from 0 to 8 as total contours are 9\n",
    "\n",
    "    cv2.drawContours(res, contours, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('result',res)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break'''\n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsv+contour+median blur in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "#cv2.namedWindow(\"Parameters\")\n",
    "#cv2.resizeWindow(\"Parameters\",640,240)\n",
    "cv2.createTrackbar(\"Threshold1\",\"Tracking\",107,255,nothing)\n",
    "cv2.createTrackbar(\"Threshold2\",\"Tracking\",114,255,nothing)\n",
    "cv2.createTrackbar(\"Area\",\"Tracking\",5000,30000,nothing)\n",
    "\n",
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) #in the last parameter we are getting all the stored contour points but if we use the other one which is cv2.CHAIN_APPROX_SIMPLE then this will compress the values and we will get lesser number of points so we write it as NONE so that we get all of the points.\n",
    "    cv2.drawContours(imgContour, contours, -1, (255, 0, 255), 7)#last 2 parameters is colour and width of boundary\n",
    "\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "        area=cv2.contourArea(cnt)\n",
    "        areaMin = cv2.getTrackbarPos(\"Area\", \"Tracking\")\n",
    "        if area>areaMin:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            #now finding the corner points but before that we need to find the length of the contours\n",
    "            peri=cv2.arcLength(cnt,True)#true basically means that the contour is closed and this will give us the value of the length of the perimeter and we will use the perimeter to approximate what type of shape this is.\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)#giving it resolution and then defining that this is a closed contour. This approximation array will have a certain amount of points and these points can determine whether its a square or any other shape.\n",
    "            print(len(approx))\n",
    "            #now lets create a bounding box\n",
    "            x, y, w, h=cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5) #2nd arg is initial points. 3rd argument is the final corner of the rectangle or the bounding box.after that color followed by width\n",
    "            #now we are going to display our values so that we can easily see the number of points detected and the area detected.\n",
    "            cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, .7,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"fruit detected: Tomato \", (x + w + 20, y + 70), cv2.FONT_HERSHEY_COMPLEX, 0.7,\n",
    "                        (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    #frame = cv2.imread('apple (281).jpg')\n",
    "    imgContour = frame.copy()\n",
    "    imgBlur = cv2.medianBlur(frame, 7)#using kernel of 7 by 7\n",
    "\n",
    "    hsv = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "    \n",
    "    l_b=np.array([l_h,l_s,l_v])\n",
    "    u_b=np.array([u_h,u_s,u_v])\n",
    "    \n",
    "    mask=cv2.inRange(hsv, l_b, u_b)\n",
    "    \n",
    "    res=cv2.bitwise_and(frame, frame,mask=mask)\n",
    "    \n",
    "    threshold1 = cv2.getTrackbarPos(\"Threshold1\", \"Tracking\")\n",
    "    threshold2 = cv2.getTrackbarPos(\"Threshold2\", \"Tracking\")\n",
    "    imgCanny = cv2.Canny(mask,threshold1,threshold2)\n",
    "    kernel = np.ones((5, 5)) #defining a kernel for the dilation function. \n",
    "    imgDil = cv2.dilate(imgCanny, kernel, iterations=1)#dilation function is used to remove noise from the image.\n",
    "    getContours(imgDil,imgContour)\n",
    "    \n",
    "    imgStack = stackImages(0.8,([frame,mask,res],\n",
    "                               [imgDil,imgCanny,imgContour]))\n",
    "    \n",
    "    cv2.imshow('median blur',imgBlur)\n",
    "    cv2.imshow('result',imgStack)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('lemons.jpeg')\n",
    "img1 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img1 = cv2.medianBlur(img1,1)\n",
    "# cv2.imshow(\"Blur\",img1)\n",
    "# cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "circles=cv2.HoughCircles(img1,cv2.HOUGH_GRADIENT,1, 30, np.array([]), 80, 20, 3, 50)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    \n",
    "    cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,str(circles.shape[1])+' lemons detected',(10,50), font, 0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imshow('detected lemons',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging two codes- pic version (trial 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#im to gray\n",
    "#mblur\n",
    "#split\n",
    "#blur\n",
    "#th1, blur,thresh_bin\n",
    "#closing morph, k1\n",
    "#opening morph, k2\n",
    "#laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"Area\",\"Tracking\",5000,30000,nothing)\n",
    "\n",
    "def getContours(img,imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) #in the last parameter we are getting all the stored contour points but if we use the other one which is cv2.CHAIN_APPROX_SIMPLE then this will compress the values and we will get lesser number of points so we write it as NONE so that we get all of the points.\n",
    "    cv2.drawContours(imgContour, contours, -1, (255, 0, 255), 7)#last 2 parameters is colour and width of boundary\n",
    "\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "        area=cv2.contourArea(cnt)\n",
    "        areaMin = cv2.getTrackbarPos(\"Area\", \"Tracking\")\n",
    "        if area>areaMin:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            #now finding the corner points but before that we need to find the length of the contours\n",
    "            peri=cv2.arcLength(cnt,True)#true basically means that the contour is closed and this will give us the value of the length of the perimeter and we will use the perimeter to approximate what type of shape this is.\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)#giving it resolution and then defining that this is a closed contour. This approximation array will have a certain amount of points and these points can determine whether its a square or any other shape.\n",
    "            print(len(approx))\n",
    "            #now lets create a bounding box\n",
    "            x, y, w, h=cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x , y ), (x + w , y + h ), (0, 255, 0), 5) #2nd arg is initial points. 3rd argument is the final corner of the rectangle or the bounding box.after that color followed by width\n",
    "            #now we are going to display our values so that we can easily see the number of points detected and the area detected.\n",
    "            cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x , y -42), cv2.FONT_HERSHEY_COMPLEX, .5,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x , y - 27), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "                        (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"fruit detected: Apple \", (x-15 , y - 12), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "                        (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "while True:\n",
    "    frame = cv2.imread('apple (281).jpg')\n",
    "    imgContour = frame.copy()\n",
    "    imgBlur = cv2.medianBlur(frame, 7)#using kernel of 7 by 7\n",
    "    \n",
    "    b, g, r = cv2.split(imgBlur)\n",
    "    blur = r-(0.5*b)-(0.5*g)\n",
    "    kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(20,20))\n",
    "    kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(70,70))\n",
    "    #thresh1 = cv2.getTrackbarPos(\"Threshold 1\", \"Threshold Values\")\n",
    "    #thresh2 = cv2.getTrackbarPos(\"Threshold 2\", \"Threshold Values\")\n",
    "    _,th1 = cv2.threshold(blur, 51, 255, cv2.THRESH_BINARY)\n",
    "    closing = cv2.morphologyEx(th1, cv2.MORPH_CLOSE, kernel1)\n",
    "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel2)\n",
    "    #opening_copy = np.uint8(opening)\n",
    "    lap = cv2.Laplacian(opening, cv2.CV_64F, ksize=3)\n",
    "    lap = np.uint8(np.absolute(lap))\n",
    "    \n",
    "    getContours(lap,imgContour)\n",
    "    '''imgStack = stackImages(0.8,([frame,imgBlur,blur],\n",
    "                               [frame,lap,imgContour]))'''\n",
    "    \n",
    "    #cv2.imshow('median blur',imgBlur)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('median blur',imgBlur)\n",
    "    cv2.imshow('mask/blur',blur)\n",
    "    cv2.imshow('laplace',lap)\n",
    "    cv2.imshow('result',imgContour)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging two codes- real time version (trial 1)\n",
    "# disadvantage - lag/slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162.4857635498047, 244.76234436035156, 230.51998901367188, 212.16000366210938)\n",
      "(168.76844787597656, 254.8934326171875, 217.22415161132812, 199.92311096191406)\n",
      "(161.68997192382812, 245.82156372070312, 225.99998474121094, 207.99998474121094)\n",
      "(166.75973510742188, 251.90298461914062, 217.22413635253906, 199.923095703125)\n",
      "(171.8720703125, 253.9703369140625, 208.78907775878906, 192.15985107421875)\n",
      "(185.2416229248047, 251.60040283203125, 200.68154907226562, 184.69805908203125)\n",
      "(194.1891326904297, 251.72021484375, 200.68154907226562, 184.69805908203125)\n",
      "(212.6831512451172, 249.726318359375, 200.68154907226562, 184.69805908203125)\n",
      "(231.9871063232422, 249.07382202148438, 200.68154907226562, 184.69805908203125)\n",
      "(257.1314697265625, 252.13296508789062, 196.74661254882812, 181.07652282714844)\n",
      "(286.271728515625, 248.65560913085938, 200.68153381347656, 184.69805908203125)\n",
      "(305.3644104003906, 250.56365966796875, 200.68153381347656, 184.69805908203125)\n",
      "(318.1469421386719, 248.42266845703125, 208.78904724121094, 192.1598358154297)\n",
      "(328.7176513671875, 245.22836303710938, 217.22412109375, 199.92308044433594)\n",
      "(338.9150085449219, 247.80859375, 217.22412109375, 199.92308044433594)\n",
      "(341.2034912109375, 247.38075256347656, 221.56858825683594, 203.92153930664062)\n",
      "(337.8780822753906, 245.4397430419922, 225.9999542236328, 207.99996948242188)\n",
      "(331.77032470703125, 247.65846252441406, 225.9999542236328, 207.99996948242188)\n",
      "(319.62139892578125, 247.84913635253906, 225.9999542236328, 207.99996948242188)\n",
      "(300.9275207519531, 248.00486755371094, 225.9999542236328, 207.99996948242188)\n",
      "(285.8363037109375, 248.3750762939453, 225.9999542236328, 207.99996948242188)\n",
      "(271.0220642089844, 248.5690460205078, 225.9999542236328, 207.99996948242188)\n",
      "(256.0021057128906, 249.69691467285156, 225.9999542236328, 207.99996948242188)\n",
      "(236.65170288085938, 251.00669860839844, 225.9999542236328, 207.99996948242188)\n",
      "(219.70819091796875, 253.90403747558594, 221.56858825683594, 203.92153930664062)\n",
      "(204.18048095703125, 253.3976593017578, 225.9999542236328, 207.99996948242188)\n",
      "(200.30984497070312, 257.5238037109375, 221.56858825683594, 203.92153930664062)\n",
      "(195.42462158203125, 257.86407470703125, 221.56858825683594, 203.92153930664062)\n",
      "(195.70858764648438, 262.89349365234375, 217.22410583496094, 199.92306518554688)\n",
      "(193.7036895751953, 262.1641540527344, 221.56857299804688, 203.92152404785156)\n",
      "(196.5347442626953, 265.123046875, 221.56857299804688, 203.92152404785156)\n",
      "(205.3802490234375, 271.6683044433594, 212.9647979736328, 196.0030059814453)\n",
      "(207.6309814453125, 268.68463134765625, 217.22410583496094, 199.92306518554688)\n",
      "(207.38043212890625, 268.21484375, 217.22410583496094, 199.92306518554688)\n",
      "(208.28594970703125, 270.1130676269531, 212.9647979736328, 196.0030059814453)\n",
      "(204.9837646484375, 269.6025390625, 212.9647979736328, 196.0030059814453)\n",
      "(194.260009765625, 268.4241943359375, 217.22410583496094, 199.92306518554688)\n",
      "(190.18685913085938, 268.55035400390625, 217.22410583496094, 199.92306518554688)\n",
      "(185.28646850585938, 270.45550537109375, 217.22410583496094, 199.92306518554688)\n",
      "(181.4913330078125, 274.75152587890625, 212.9647979736328, 196.0030059814453)\n",
      "(172.84866333007812, 274.2880859375, 217.22410583496094, 199.92306518554688)\n",
      "(161.68350219726562, 275.01776123046875, 217.22410583496094, 199.92306518554688)\n",
      "(146.3870086669922, 274.4808349609375, 221.56857299804688, 203.92152404785156)\n",
      "(143.08189392089844, 276.63909912109375, 217.22409057617188, 199.9230499267578)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "############### Tracker Types #####################\n",
    "\n",
    "#tracker = cv2.TrackerBoosting_create()\n",
    "#tracker = cv2.TrackerMIL_create()\n",
    "#tracker = cv2.TrackerKCF_create()\n",
    "#tracker = cv2.TrackerTLD_create()\n",
    "#tracker = cv2.TrackerMedianFlow_create()\n",
    "#tracker = cv2.TrackerCSRT_create()\n",
    "\n",
    "\n",
    "########################################################\n",
    "\n",
    "#refer to the blog for tracker description-https://ehsangazar.com/object-tracking-with-opencv-fd18ccdd7369\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#tracker=cv2.TrackerMOSSE_create() #speed is high but accuracy is low\n",
    "tracker = cv2.TrackerCSRT_create()#accuracy is high but the speed is low\n",
    "\n",
    "success, img=cap.read()\n",
    "bbox=cv2.selectROI('Tracking',img,False)\n",
    "tracker.init(img,bbox)\n",
    "\n",
    "def drawBox(img,bbox):\n",
    "    x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "    cv2.rectangle(img, (x, y), ((x + w), (y + h)), (255, 0, 255), 3, 3 )#color\n",
    "    cv2.putText(img, \"Tracking\", (100, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "while True:\n",
    "    timer = cv2.getTickCount()\n",
    "    success, img=cap.read()\n",
    "    \n",
    "    success,bbox=tracker.update(img) #bbox is basically a touple\n",
    "    print(bbox)\n",
    "    \n",
    "    if success:\n",
    "        drawBox(img,bbox)\n",
    "    else:\n",
    "        cv2.putText(img, \"Lost\", (100, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    "    cv2.putText(img,str(int(fps)), (75, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2);#scale, color, thickness\n",
    "    cv2.imshow('tracking',img)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549, 32)\n",
      "[ 86 180 184 178 153 236  17  11 187  63 139  25 134 255  72  90 129 151\n",
      " 109 145  58  75 154  18 217 246 123 255 128  64 135  83]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img1 = cv2.imread('apple (281).jpg',0)\n",
    "#img2 = cv2.imread('ImagesTrain/Kinect.jpg',0)\n",
    "img2 = cv2.imread('damaged_apple (263).jpg',0)\n",
    " \n",
    "orb = cv2.ORB_create(nfeatures=1000)\n",
    " \n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "# imgKp1 = cv2.drawKeypoints(img1,kp1,None)\n",
    "# imgKp2 = cv2.drawKeypoints(img2,kp2,None)\n",
    "print(des1.shape) #gives number of features and each feature is described in 32 values \n",
    "print(des1[0])\n",
    "\n",
    "bf = cv2.BFMatcher()#brute force matcher\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "\n",
    "#going through all the matches\n",
    "good = []\n",
    "for m,n in matches: #since we set k=2, we have 2 values that we can unpack\n",
    "    if m.distance < 0.75*n.distance: #if distance between them is low then we are going to say that it is a good match. if dist between them is high then it is a bad match\n",
    "        good.append([m])\n",
    "print(len(good))\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)\n",
    " \n",
    "# cv2.imshow('Kp1',imgKp1)\n",
    "# cv2.imshow('Kp2',imgKp2)\n",
    "cv2.imshow('img1',img1)\n",
    "cv2.imshow('img2',img2)\n",
    "cv2.imshow('img3',img3)\n",
    "k = cv2.waitKey(1) & 0xFF\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matching in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes Detected 5\n",
      "['apple (184)', 'apple (191)', 'apple (281)', 'damaged_apple (263)', 'damaged_apple (28)']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    " \n",
    "current_path = os.getcwd()\n",
    "orb = cv2.ORB_create(nfeatures=1000)\n",
    " \n",
    "#### Import Images\n",
    "images = []\n",
    "classNames= []\n",
    "folder = os.path.join(current_path, 'images')\n",
    "myList = os.listdir(folder)\n",
    "#print(myList)\n",
    "print('Total Classes Detected', len(myList))\n",
    "for cl in myList:\n",
    "    imgCur = cv2.imread(f'{folder}/{cl}',0)# 0 is for gray scale\n",
    "    images.append(imgCur)\n",
    "    classNames.append(os.path.splitext(cl)[0])#storing without the file extension\n",
    "print(classNames)\n",
    "\n",
    "#now lets find all the descriptors of the given image\n",
    "\n",
    "def findDes(images):\n",
    "    desList=[]\n",
    "    for img in images:\n",
    "        kp,des = orb.detectAndCompute(img,None)\n",
    "        desList.append(des)\n",
    "    return desList\n",
    "\n",
    "def findID(img, desList,thres=5):\n",
    "    kp2,des2 = orb.detectAndCompute(img,None)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matchList=[]\n",
    "    finalVal = -1\n",
    "    try:\n",
    "        for des in desList:\n",
    "            matches = bf.knnMatch(des, des2, k=2)\n",
    "            good = []\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.75 * n.distance:\n",
    "                    good.append([m])\n",
    "            matchList.append(len(good))\n",
    "    except:\n",
    "        pass\n",
    "    # print(matchList)\n",
    "    if len(matchList)!=0:\n",
    "        if max(matchList) > thres:\n",
    "            finalVal = matchList.index(max(matchList)) #finding the index of the maximum value of matchList\n",
    "    return finalVal\n",
    "\n",
    "desList=findDes(images)\n",
    "print(len(desList))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    " \n",
    "    success, img2 = cap.read()\n",
    "    imgOriginal = img2.copy()\n",
    "    img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    id = findID(img2,desList)\n",
    "    if id != -1:\n",
    "        cv2.putText(imgOriginal,classNames[id],(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255),2)# scale, color and thickness\n",
    " \n",
    " \n",
    "    cv2.imshow('img2',imgOriginal)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
